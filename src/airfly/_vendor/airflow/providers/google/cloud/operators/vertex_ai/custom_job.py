# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.providers.google.cloud.operators.cloud_base import (
    GoogleCloudBaseOperator,
)


class CustomTrainingJobBaseOperator(GoogleCloudBaseOperator):
    project_id: "str"
    region: "str"
    display_name: "str"
    container_uri: "str"
    model_serving_container_image_uri: "str | None"
    model_serving_container_predict_route: "str | None"
    model_serving_container_health_route: "str | None"
    model_serving_container_command: "Sequence[str] | None"
    model_serving_container_args: "Sequence[str] | None"
    model_serving_container_environment_variables: "dict[str, str] | None"
    model_serving_container_ports: "Sequence[int] | None"
    model_description: "str | None"
    model_instance_schema_uri: "str | None"
    model_parameters_schema_uri: "str | None"
    model_prediction_schema_uri: "str | None"
    parent_model: "str | None"
    is_default_version: "bool | None"
    model_version_aliases: "list[str] | None"
    model_version_description: "str | None"
    labels: "dict[str, str] | None"
    training_encryption_spec_key_name: "str | None"
    model_encryption_spec_key_name: "str | None"
    staging_bucket: "str | None"
    dataset_id: "str | None"
    annotation_schema_uri: "str | None"
    model_display_name: "str | None"
    model_labels: "dict[str, str] | None"
    base_output_dir: "str | None"
    service_account: "str | None"
    network: "str | None"
    bigquery_destination: "str | None"
    args: "list[str | float | int] | None"
    environment_variables: "dict[str, str] | None"
    replica_count: "int"
    machine_type: "str"
    accelerator_type: "str"
    accelerator_count: "int"
    boot_disk_type: "str"
    boot_disk_size_gb: "int"
    training_fraction_split: "float | None"
    validation_fraction_split: "float | None"
    test_fraction_split: "float | None"
    training_filter_split: "str | None"
    validation_filter_split: "str | None"
    test_filter_split: "str | None"
    predefined_split_column_name: "str | None"
    timestamp_split_column_name: "str | None"
    tensorboard: "str | None"
    sync: "_empty"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class CreateCustomContainerTrainingJobOperator(CustomTrainingJobBaseOperator):
    command: "Sequence[str]"
    region: "str"
    parent_model: "str | None"
    impersonation_chain: "str | Sequence[str] | None"
    dataset_id: "str | None"
    deferrable: "bool"
    poll_interval: "int"


class CreateCustomPythonPackageTrainingJobOperator(CustomTrainingJobBaseOperator):
    python_package_gcs_uri: "str"
    python_module_name: "str"
    region: "str"
    parent_model: "str | None"
    impersonation_chain: "str | Sequence[str] | None"
    dataset_id: "str | None"
    deferrable: "bool"
    poll_interval: "int"


class CreateCustomTrainingJobOperator(CustomTrainingJobBaseOperator):
    script_path: "str"
    requirements: "Sequence[str] | None"
    region: "str"
    parent_model: "str | None"
    impersonation_chain: "str | Sequence[str] | None"
    dataset_id: "str | None"
    deferrable: "bool"
    poll_interval: "int"


class DeleteCustomTrainingJobOperator(GoogleCloudBaseOperator):
    training_pipeline_id: "str"
    custom_job_id: "str"
    region: "str"
    project_id: "str"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class ListCustomTrainingJobOperator(GoogleCloudBaseOperator):
    region: "str"
    project_id: "str"
    page_size: "int | None"
    page_token: "str | None"
    filter: "str | None"
    read_mask: "str | None"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"

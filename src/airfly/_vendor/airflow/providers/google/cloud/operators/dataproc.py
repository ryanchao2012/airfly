# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.providers.google.cloud.operators.cloud_base import (
    GoogleCloudBaseOperator,
)


class DataprocCreateClusterOperator(GoogleCloudBaseOperator):
    cluster_name: "str"
    region: "str"
    project_id: "str"
    cluster_config: "dict | Cluster | None"
    virtual_cluster_config: "dict | None"
    labels: "dict | None"
    request_id: "str | None"
    delete_on_error: "bool"
    use_if_exists: "bool"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"


class DataprocScaleClusterOperator(GoogleCloudBaseOperator):
    pass


class DataprocDeleteClusterOperator(GoogleCloudBaseOperator):
    region: "str"
    cluster_name: "str"
    project_id: "str"
    cluster_uuid: "str | None"
    request_id: "str | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"


class _DataprocStartStopClusterBaseOperator(GoogleCloudBaseOperator):
    cluster_name: "str"
    region: "str"
    project_id: "str"
    cluster_uuid: "str | None"
    request_id: "str | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocStartClusterOperator(_DataprocStartStopClusterBaseOperator):
    cluster_name: "str"
    region: "str"
    project_id: "str"
    cluster_uuid: "str | None"
    request_id: "str | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocStopClusterOperator(_DataprocStartStopClusterBaseOperator):
    cluster_name: "str"
    region: "str"
    project_id: "str"
    cluster_uuid: "str | None"
    request_id: "str | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocJobBaseOperator(GoogleCloudBaseOperator):
    region: "str"
    job_name: "str"
    cluster_name: "str"
    project_id: "str"
    dataproc_properties: "dict | None"
    dataproc_jars: "list[str] | None"
    gcp_conn_id: "str"
    labels: "dict | None"
    job_error_states: "set[str] | None"
    impersonation_chain: "str | Sequence[str] | None"
    asynchronous: "bool"
    deferrable: "bool"
    polling_interval_seconds: "int"


class DataprocSubmitPigJobOperator(DataprocJobBaseOperator):
    pass


class DataprocSubmitHiveJobOperator(DataprocJobBaseOperator):
    pass


class DataprocSubmitSparkSqlJobOperator(DataprocJobBaseOperator):
    pass


class DataprocSubmitSparkJobOperator(DataprocJobBaseOperator):
    pass


class DataprocSubmitHadoopJobOperator(DataprocJobBaseOperator):
    pass


class DataprocSubmitPySparkJobOperator(DataprocJobBaseOperator):
    pass


class DataprocCreateWorkflowTemplateOperator(GoogleCloudBaseOperator):
    template: "dict"
    region: "str"
    project_id: "str"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocInstantiateWorkflowTemplateOperator(GoogleCloudBaseOperator):
    template_id: "str"
    region: "str"
    project_id: "str"
    version: "int | None"
    request_id: "str | None"
    parameters: "dict[str, str] | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"
    cancel_on_kill: "bool"


class DataprocInstantiateInlineWorkflowTemplateOperator(GoogleCloudBaseOperator):
    template: "dict"
    region: "str"
    project_id: "str"
    request_id: "str | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"
    cancel_on_kill: "bool"


class DataprocSubmitJobOperator(GoogleCloudBaseOperator):
    job: "dict"
    region: "str"
    project_id: "str"
    request_id: "str | None"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    asynchronous: "bool"
    deferrable: "bool"
    polling_interval_seconds: "int"
    cancel_on_kill: "bool"
    wait_timeout: "int | None"


class DataprocUpdateClusterOperator(GoogleCloudBaseOperator):
    cluster_name: "str"
    cluster: "dict | Cluster"
    update_mask: "dict | FieldMask"
    graceful_decommission_timeout: "dict | Duration"
    region: "str"
    request_id: "str | None"
    project_id: "str"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"


class DataprocDiagnoseClusterOperator(GoogleCloudBaseOperator):
    region: "str"
    cluster_name: "str"
    project_id: "str"
    tarball_gcs_dir: "str | None"
    diagnosis_interval: "dict | Interval | None"
    jobs: "MutableSequence[str] | None"
    yarn_application_ids: "MutableSequence[str] | None"
    retry: "AsyncRetry | _MethodDefault"
    timeout: "float"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    deferrable: "bool"
    polling_interval_seconds: "int"


class DataprocCreateBatchOperator(GoogleCloudBaseOperator):
    region: "str | None"
    project_id: "str"
    batch: "dict | Batch"
    batch_id: "str"
    request_id: "str | None"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    result_retry: "AsyncRetry | _MethodDefault | Retry"
    asynchronous: "bool"
    deferrable: "bool"
    polling_interval_seconds: "int"


class DataprocDeleteBatchOperator(GoogleCloudBaseOperator):
    batch_id: "str"
    region: "str"
    project_id: "str"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocGetBatchOperator(GoogleCloudBaseOperator):
    batch_id: "str"
    region: "str"
    project_id: "str"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"


class DataprocListBatchesOperator(GoogleCloudBaseOperator):
    region: "str"
    project_id: "str"
    page_size: "int | None"
    page_token: "str | None"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"
    filter: "str | None"
    order_by: "str | None"


class DataprocCancelOperationOperator(GoogleCloudBaseOperator):
    operation_name: "str"
    region: "str"
    project_id: "str"
    retry: "Retry | _MethodDefault"
    timeout: "float | None"
    metadata: "Sequence[tuple[str, str]]"
    gcp_conn_id: "str"
    impersonation_chain: "str | Sequence[str] | None"

# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.models.baseoperator import BaseOperator


class GCSToBigQueryOperator(BaseOperator):
    bucket: "_empty"
    source_objects: "_empty"
    destination_project_dataset_table: "_empty"
    schema_fields: "_empty"
    schema_object: "_empty"
    schema_object_bucket: "_empty"
    source_format: "_empty"
    compression: "_empty"
    create_disposition: "_empty"
    skip_leading_rows: "_empty"
    write_disposition: "_empty"
    field_delimiter: "_empty"
    max_bad_records: "_empty"
    quote_character: "_empty"
    ignore_unknown_values: "_empty"
    allow_quoted_newlines: "_empty"
    allow_jagged_rows: "_empty"
    encoding: "_empty"
    max_id_key: "_empty"
    gcp_conn_id: "_empty"
    schema_update_options: "_empty"
    src_fmt_configs: "_empty"
    external_table: "_empty"
    time_partitioning: "_empty"
    cluster_fields: "_empty"
    autodetect: "_empty"
    encryption_configuration: "_empty"
    location: "_empty"
    impersonation_chain: "str | Sequence[str] | None"
    labels: "_empty"
    description: "_empty"
    deferrable: "bool"
    result_retry: "Retry"
    result_timeout: "float | None"
    cancel_on_kill: "bool"
    job_id: "str | None"
    force_rerun: "bool"
    reattach_states: "set[str] | None"
    project_id: "str"

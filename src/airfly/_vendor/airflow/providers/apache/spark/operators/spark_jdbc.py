# Auto generated by 'inv collect-airflow'
from airfly._vendor.airflow.providers.apache.spark.operators.spark_submit import (
    SparkSubmitOperator,
)


class SparkJDBCOperator(SparkSubmitOperator):
    spark_app_name: "str"
    spark_conn_id: "str"
    spark_conf: "dict[str, Any] | None"
    spark_py_files: "str | None"
    spark_files: "str | None"
    spark_jars: "str | None"
    cmd_type: "str"
    jdbc_table: "str | None"
    jdbc_conn_id: "str"
    jdbc_driver: "str | None"
    metastore_table: "str | None"
    jdbc_truncate: "bool"
    save_mode: "str | None"
    save_format: "str | None"
    batch_size: "int | None"
    fetch_size: "int | None"
    num_partitions: "int | None"
    partition_column: "str | None"
    lower_bound: "str | None"
    upper_bound: "str | None"
    create_table_column_types: "str | None"
